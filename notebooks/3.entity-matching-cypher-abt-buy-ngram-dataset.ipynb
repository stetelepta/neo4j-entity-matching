{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7e7b80-d626-4094-86e9-c62bca2c997c",
   "metadata": {},
   "source": [
    "# Entity Matching using Neo4j - Rare ngrams\n",
    "\n",
    "_Salomon Tetelepta, May 4th 2024_\n",
    "* Notebook to improve the model by enrich the graph\n",
    "    * detect model numbers based on ngram rarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b93c37-f0a9-46c8-82e9-dd7ff1f6f2f0",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722da72e-0aaf-4023-bdc4-22853d1c9cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo4j: 5.17.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j python-dotenv langchain-community --quiet\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -p neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f718c68-90df-407e-87e3-8235c2f06180",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a5300d-35fe-4929-b7a8-ded5d5d64a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from pathlib import Path\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from wordfreq import lossy_tokenize, tokenize, word_frequency\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import neo4j\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836fbd4-fa26-49c7-b758-d01d2fc2e97c",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d7b49c-ce17-42d0-85cc-fe21f86a8318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path settings\n",
    "project_path = Path(os.getcwd()).parent\n",
    "data_path = project_path / \"data\"\n",
    "output_path = project_path / \"output\"\n",
    "\n",
    "database = \"abt-buy\"\n",
    "\n",
    "# load env settings\n",
    "load_dotenv(project_path / \".env\")\n",
    "\n",
    "# reproducability\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbe0a7-229a-47b5-8f9c-88bb567b0889",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d3c50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_buy.csv', '1_abt.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path / 'abt-buy' / 'record_descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4237c131-bcea-41b1-8664-881d6315ebf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>description_x</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price_x</th>\n",
       "      <th>subject_id_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>description_y</th>\n",
       "      <th>price_y</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207390654</td>\n",
       "      <td>Sony Handycam HDR-SR10 High Definition Digital...</td>\n",
       "      <td>16:9 - 2.7' Hybrid LCD</td>\n",
       "      <td>Sony</td>\n",
       "      <td>549.0</td>\n",
       "      <td>33161</td>\n",
       "      <td>Sony High Definition HDV Handycam Camcorder - ...</td>\n",
       "      <td>Sony High Definition HDV Handycam Camcorder - ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33161</td>\n",
       "      <td>207390654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208085180</td>\n",
       "      <td>Pioneer DEH-2000MP Car Audio Player</td>\n",
       "      <td>CD-RW - CD-Text, MP3, WMA, WAV - LCD - 4 - 200...</td>\n",
       "      <td>Pioneer</td>\n",
       "      <td>84.0</td>\n",
       "      <td>36258</td>\n",
       "      <td>D-Link Broadband Cable Modem - DCM202</td>\n",
       "      <td>D-Link Broadband Cable Modem - DCM202/ DOCSIS ...</td>\n",
       "      <td>79.00</td>\n",
       "      <td>36258</td>\n",
       "      <td>208085180</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90125786</td>\n",
       "      <td>Sanus Wall/Ceiling Speaker Mount - WMS3S SILVER</td>\n",
       "      <td>Plastic - 8 lb</td>\n",
       "      <td>Sanus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17417</td>\n",
       "      <td>Sanus 13' - 30' VisionMount Flat Panel TV Silv...</td>\n",
       "      <td>Sanus 13' - 30' VisionMount Flat Panel TV Silv...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>17417</td>\n",
       "      <td>90125786</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id_x                                             name_x  \\\n",
       "0     207390654  Sony Handycam HDR-SR10 High Definition Digital...   \n",
       "1     208085180                Pioneer DEH-2000MP Car Audio Player   \n",
       "2      90125786    Sanus Wall/Ceiling Speaker Mount - WMS3S SILVER   \n",
       "\n",
       "                                       description_x manufacturer  price_x  \\\n",
       "0                             16:9 - 2.7' Hybrid LCD         Sony    549.0   \n",
       "1  CD-RW - CD-Text, MP3, WMA, WAV - LCD - 4 - 200...      Pioneer     84.0   \n",
       "2                                     Plastic - 8 lb        Sanus      NaN   \n",
       "\n",
       "   subject_id_y                                             name_y  \\\n",
       "0         33161  Sony High Definition HDV Handycam Camcorder - ...   \n",
       "1         36258              D-Link Broadband Cable Modem - DCM202   \n",
       "2         17417  Sanus 13' - 30' VisionMount Flat Panel TV Silv...   \n",
       "\n",
       "                                       description_y  price_y  source_id  \\\n",
       "0  Sony High Definition HDV Handycam Camcorder - ...      NaN      33161   \n",
       "1  D-Link Broadband Cable Modem - DCM202/ DOCSIS ...    79.00      36258   \n",
       "2  Sanus 13' - 30' VisionMount Flat Panel TV Silv...    39.99      17417   \n",
       "\n",
       "   target_id  matching  \n",
       "0  207390654     False  \n",
       "1  208085180     False  \n",
       "2   90125786     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abt and buy records\n",
    "df_abt = pd.read_csv(data_path / 'abt-buy' / 'record_descriptions' / '1_abt.csv', encoding='unicode_escape')\n",
    "df_buy = pd.read_csv(data_path / 'abt-buy' / 'record_descriptions' / '2_buy.csv')\n",
    "\n",
    "# matches - train and validation set\n",
    "df_train = pd.read_csv(data_path / 'abt-buy' / 'gs_train.csv')\n",
    "df_val = pd.read_csv(data_path / 'abt-buy' / 'gs_val.csv')\n",
    "df_test = pd.read_csv(data_path / 'abt-buy' / 'gs_test.csv')\n",
    "\n",
    "# merge records with matches\n",
    "df_abt_merged = df_abt.merge(df_train, left_on='subject_id', right_on='source_id', how='right')\n",
    "df_train_merged = df_buy.merge(df_abt_merged, left_on='subject_id', right_on='target_id', how='right')\n",
    "\n",
    "df_train_merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124aa4ad-667e-4c84-a38c-44c27a3e7fbe",
   "metadata": {},
   "source": [
    "### Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70a5c39-9f21-49b4-905e-1385499f93e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database: abt-buy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'count(n)': 612119}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv('NEO4J_URL'),\n",
    "    username=os.getenv('NEO4J_USER'),\n",
    "    password=os.getenv('NEO4J_PASS')\n",
    ")\n",
    "\n",
    "# create database if does not exist\n",
    "graph._database = \"system\"\n",
    "query = f\"CREATE DATABASE `{database}` IF NOT EXISTS\"\n",
    "graph.query(query)\n",
    "\n",
    "# change to target database\n",
    "graph._database = database\n",
    "print(\"database:\", graph._database)\n",
    "\n",
    "# check nr nodes in the graph\n",
    "graph.query(\"MATCH (n) RETURN count(n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255543f",
   "metadata": {},
   "source": [
    "### Create Ngram dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80b1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from itertools import islice, tee\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1e4824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 11.2 s\n",
    "\n",
    "run_cell = False\n",
    "if run_cell == True:\n",
    "    nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff75e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(s, n):\n",
    "    ngrams = list(zip(*(islice(seq, index, None) for index, seq in enumerate(tee(s, n)))))\n",
    "    return [\"\".join(n) for n in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d1a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_words = None\n",
    "list_words = [w.lower() for w in words.words()[:nr_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46c9491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.02 s, sys: 110 ms, total: 6.13 s\n",
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 5.99 s\n",
    "\n",
    "nr_words = None\n",
    "list_words = [w.lower() for w in words.words()[:nr_words]]\n",
    "\n",
    "output = []\n",
    "for n in np.arange(3, 7):\n",
    "    dict_ngrams = defaultdict(int)\n",
    "    dict_ngrams\n",
    "    for w in list_words:\n",
    "        for ngram in get_ngrams(w, n=n):\n",
    "            dict_ngrams[ngram] += 1\n",
    "\n",
    "    df_ngrams = pd.DataFrame([dict_ngrams]).T.sort_values(0, ascending=False).rename(columns={0: 'count'})\n",
    "    df_ngrams['n'] = n\n",
    "    output.append(df_ngrams)\n",
    "df_ngrams_all = pd.concat(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62181c41",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af9920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngrams_all.reset_index(names='ngram').to_csv(output_path / 'ngrams.csv', index=False)\n",
    "df_ngrams_all = pd.read_csv(output_path / 'ngrams.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7dea85",
   "metadata": {},
   "source": [
    "### Add ngrams to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5c7d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>count</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ess</td>\n",
       "      <td>10976</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ion</td>\n",
       "      <td>9704</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ter</td>\n",
       "      <td>9546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ati</td>\n",
       "      <td>9473</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ing</td>\n",
       "      <td>8951</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram  count  n\n",
       "0   ess  10976  3\n",
       "1   ion   9704  3\n",
       "2   ter   9546  3\n",
       "3   ati   9473  3\n",
       "4   ing   8951  3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngrams_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57701353",
   "metadata": {},
   "source": [
    "#### Add unique constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c05156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE CONSTRAINT ngram_value IF NOT EXISTS FOR (ngram:Ngram) REQUIRE ngram.value IS UNIQUE\"\n",
    "graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9409fae",
   "metadata": {},
   "source": [
    "#### brute force ngrams to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b70d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 3 µs, total: 9 µs\n",
      "Wall time: 17.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 2h 42min 10s\n",
    "\n",
    "run_cell = False\n",
    "if run_cell:\n",
    "    for i, (idx, row) in enumerate(df_ngrams_all.iterrows()):\n",
    "        if i % 50_000 == 0:\n",
    "            print(f\"{i} / {len(df_ngrams_all):,}\")\n",
    "        query = f\"MERGE (ngram:Ngram {{value: '{ row['ngram']}', count: {row['count']} }})\"\n",
    "        graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c072ce",
   "metadata": {},
   "source": [
    "### Split WordLower nodes into Ngrams\n",
    "\n",
    "* Create relationships `(:WordLower)-[:HAS_[N]GRAM]->(:Ngram)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a691d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordlower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turntable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pslx350h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pslx350h/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wordlower\n",
       "0       sony\n",
       "1  turntable\n",
       "2          -\n",
       "3   pslx350h\n",
       "4  pslx350h/"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"MATCH (w:WordLower) RETURN w.value AS wordlower\"\"\"\n",
    "results = graph.query(query)\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a9e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordlower</th>\n",
       "      <th>3gram</th>\n",
       "      <th>4gram</th>\n",
       "      <th>5gram</th>\n",
       "      <th>6gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sony</td>\n",
       "      <td>[son, ony]</td>\n",
       "      <td>[sony]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turntable</td>\n",
       "      <td>[tur, urn, rnt, nta, tab, abl, ble]</td>\n",
       "      <td>[turn, urnt, rnta, ntab, tabl, able]</td>\n",
       "      <td>[turnt, urnta, rntab, ntabl, table]</td>\n",
       "      <td>[turnta, urntab, rntabl, ntable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pslx350h</td>\n",
       "      <td>[psl, slx, lx3, x35, 350, 50h]</td>\n",
       "      <td>[pslx, slx3, lx35, x350, 350h]</td>\n",
       "      <td>[pslx3, slx35, lx350, x350h]</td>\n",
       "      <td>[pslx35, slx350, lx350h]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pslx350h/</td>\n",
       "      <td>[psl, slx, lx3, x35, 350, 50h, 0h/]</td>\n",
       "      <td>[pslx, slx3, lx35, x350, 350h, 50h/]</td>\n",
       "      <td>[pslx3, slx35, lx350, x350h, 350h/]</td>\n",
       "      <td>[pslx35, slx350, lx350h, x350h/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9711</th>\n",
       "      <td>mb942z/a</td>\n",
       "      <td>[mb9, b94, 942, 42z, 2z/, z/a]</td>\n",
       "      <td>[mb94, b942, 942z, 42z/, 2z/a]</td>\n",
       "      <td>[mb942, b942z, 942z/, 42z/a]</td>\n",
       "      <td>[mb942z, b942z/, 942z/a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9712</th>\n",
       "      <td>pack-int</td>\n",
       "      <td>[pac, ack, ck-, k-i, -in, int]</td>\n",
       "      <td>[pack, ack-, ck-i, k-in, -int]</td>\n",
       "      <td>[pack-, ack-i, ck-in, k-int]</td>\n",
       "      <td>[pack-i, ack-in, ck-int]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9713</th>\n",
       "      <td>mb943z/a</td>\n",
       "      <td>[mb9, b94, 943, 43z, 3z/, z/a]</td>\n",
       "      <td>[mb94, b943, 943z, 43z/, 3z/a]</td>\n",
       "      <td>[mb943, b943z, 943z/, 43z/a]</td>\n",
       "      <td>[mb943z, b943z/, 943z/a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9714</th>\n",
       "      <td>mate</td>\n",
       "      <td>[mat, ate]</td>\n",
       "      <td>[mate]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>iph3gc-bcf</td>\n",
       "      <td>[iph, ph3, h3g, 3gc, gc-, c-b, -bc, bcf]</td>\n",
       "      <td>[iph3, ph3g, h3gc, 3gc-, gc-b, c-bc, -bcf]</td>\n",
       "      <td>[iph3g, ph3gc, h3gc-, 3gc-b, gc-bc, c-bcf]</td>\n",
       "      <td>[iph3gc, ph3gc-, h3gc-b, 3gc-bc, gc-bcf]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9716 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wordlower                                     3gram  \\\n",
       "0           sony                                [son, ony]   \n",
       "1      turntable       [tur, urn, rnt, nta, tab, abl, ble]   \n",
       "2              -                                        []   \n",
       "3       pslx350h            [psl, slx, lx3, x35, 350, 50h]   \n",
       "4      pslx350h/       [psl, slx, lx3, x35, 350, 50h, 0h/]   \n",
       "...          ...                                       ...   \n",
       "9711    mb942z/a            [mb9, b94, 942, 42z, 2z/, z/a]   \n",
       "9712    pack-int            [pac, ack, ck-, k-i, -in, int]   \n",
       "9713    mb943z/a            [mb9, b94, 943, 43z, 3z/, z/a]   \n",
       "9714        mate                                [mat, ate]   \n",
       "9715  iph3gc-bcf  [iph, ph3, h3g, 3gc, gc-, c-b, -bc, bcf]   \n",
       "\n",
       "                                           4gram  \\\n",
       "0                                         [sony]   \n",
       "1           [turn, urnt, rnta, ntab, tabl, able]   \n",
       "2                                             []   \n",
       "3                 [pslx, slx3, lx35, x350, 350h]   \n",
       "4           [pslx, slx3, lx35, x350, 350h, 50h/]   \n",
       "...                                          ...   \n",
       "9711              [mb94, b942, 942z, 42z/, 2z/a]   \n",
       "9712              [pack, ack-, ck-i, k-in, -int]   \n",
       "9713              [mb94, b943, 943z, 43z/, 3z/a]   \n",
       "9714                                      [mate]   \n",
       "9715  [iph3, ph3g, h3gc, 3gc-, gc-b, c-bc, -bcf]   \n",
       "\n",
       "                                           5gram  \\\n",
       "0                                             []   \n",
       "1            [turnt, urnta, rntab, ntabl, table]   \n",
       "2                                             []   \n",
       "3                   [pslx3, slx35, lx350, x350h]   \n",
       "4            [pslx3, slx35, lx350, x350h, 350h/]   \n",
       "...                                          ...   \n",
       "9711                [mb942, b942z, 942z/, 42z/a]   \n",
       "9712                [pack-, ack-i, ck-in, k-int]   \n",
       "9713                [mb943, b943z, 943z/, 43z/a]   \n",
       "9714                                          []   \n",
       "9715  [iph3g, ph3gc, h3gc-, 3gc-b, gc-bc, c-bcf]   \n",
       "\n",
       "                                         6gram  \n",
       "0                                           []  \n",
       "1             [turnta, urntab, rntabl, ntable]  \n",
       "2                                           []  \n",
       "3                     [pslx35, slx350, lx350h]  \n",
       "4             [pslx35, slx350, lx350h, x350h/]  \n",
       "...                                        ...  \n",
       "9711                  [mb942z, b942z/, 942z/a]  \n",
       "9712                  [pack-i, ack-in, ck-int]  \n",
       "9713                  [mb943z, b943z/, 943z/a]  \n",
       "9714                                        []  \n",
       "9715  [iph3gc, ph3gc-, h3gc-b, 3gc-bc, gc-bcf]  \n",
       "\n",
       "[9716 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in np.arange(3, 7):\n",
    "    df_results.loc[:, f'{n}gram'] = df_results['wordlower'].apply(lambda x: get_ngrams(x, n))\n",
    "    \n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2675fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 21min 22s\n",
    "\n",
    "run_cell = False\n",
    "if run_cell:\n",
    "    for i, (idx, row) in enumerate(df_results.iterrows()):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"{i}/{len(df_results)}\")\n",
    "\n",
    "        for n in np.arange(3, 7):\n",
    "            for ngram in row[f'{n}gram']:\n",
    "                value = row['wordlower'].replace(\"'\", \"\\\\'\")\n",
    "                ngram = ngram.replace(\"'\", \"\\\\'\")\n",
    "\n",
    "                query = f\"\"\"\n",
    "                MATCH (w:WordLower) WHERE w.value = '{value}'\n",
    "                MERGE (ngram:Ngram {{value: '{ngram}'}})\n",
    "                MERGE (w)-[:HAS_{n}GRAM]->(ngram)\n",
    "                SET w:PROCESSED\n",
    "                RETURN count(ngram)\n",
    "                \"\"\"\n",
    "                graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94977a8",
   "metadata": {},
   "source": [
    "#### Label rare ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b970b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, label ngrams that have a count attribute, which means they appeared in the vocabulary\n",
    "query = \"MATCH (n:Ngram) WHERE n.count > 0 SET n:Vocab\"\n",
    "graph.query(query)\n",
    "\n",
    "# next, label rare ngrams, the ones that do not appear in the vocabulary\n",
    "query = \"MATCH (n:Ngram) WHERE NOT n:Vocab SET n:NoVocab\"\n",
    "graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9cac6",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f878349",
   "metadata": {},
   "source": [
    "<h4>Can we find model IDs and other reference ids by checking for rare ngrams that words have in common?</h4>\n",
    "<img src=\"../images/7.1-example-sharing-multiple-rare-3grams.jpg\" width=\"600\">\n",
    "\n",
    "<h4>Example of matches that share a rare ngram </h4>\n",
    "<img src=\"../images/7.2-example-sharing-multiple-rare-3grams.jpg\" width=\"600\">\n",
    "\n",
    "<pre>MATCH p=(ngram:NoVocab)<-[]-(:WordLower)<-[:HAS_WORD_LOWER]-(:Name)<-[:HAS_NAME]-(i1:Item)-[:IS_MATCH]-(i2:Item)-[:HAS_NAME]->(:Name)-[:HAS_WORD_LOWER]->(:WordLower)-[]->(ngram) RETURN p LIMIT 10</pre>\n",
    "\n",
    "<h4>Example of no matches that share a rare ngram </h4>\n",
    "<img src=\"../images/7.2-example-sharing-multiple-rare-3grams.jpg\" width=\"600\">\n",
    "\n",
    "<pre>MATCH p=(ngram:NoVocab)<-[]-(:WordLower)<-[:HAS_WORD_LOWER]-(:Name)<-[:HAS_NAME]-(i1:Item)-[:NO_MATCH]-(i2:Item)-[:HAS_NAME]->(:Name)-[:HAS_WORD_LOWER]->(:WordLower)-[]->(ngram) RETURN p LIMIT 10</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e066ca",
   "metadata": {},
   "source": [
    "<h4>Example of no matches that share a rare ngram </h4>\n",
    "<img src=\"../images/7.4-example-sharing-multiple-rare-3grams.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0595ad87",
   "metadata": {},
   "source": [
    "<h4>Example of an incorrect match where there is a crucial difference</h4>\n",
    "<img src=\"../images/7.5-example-crucial-difference.jpg\" width=\"600\">\n",
    "\n",
    "<h4>Example of an incorrect match where there is a common 6gram</h4>\n",
    "<img src=\"../images/7.6-example-common-6gram.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af956eab",
   "metadata": {},
   "source": [
    "### Evaluate query that takes into account sharing rare ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230b336",
   "metadata": {},
   "source": [
    "#### Create relations between items that share rare ngrams\n",
    "\n",
    "* New model extends the previous model using a UNION ALL\n",
    "* Above the threshold of 6 additional rule is to check for shared ngrams of a certain size {4, 5, 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78556191",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "630b0f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_threshold_4gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>215</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model threshold      prec    recall    fscore  \\\n",
       "0  shared_word_lower_threshold_4gram   (6, 47)  0.669782  0.903361  0.769231   \n",
       "\n",
       "  evaluated_on   tp   fp  fn   tn  \n",
       "0      testset  215  106  23  543  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_threshold_5gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>testset</td>\n",
       "      <td>184</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shared_word_lower_threshold_4gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>215</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model threshold      prec    recall    fscore  \\\n",
       "0  shared_word_lower_threshold_5gram   (6, 47)  0.727273  0.880383  0.796537   \n",
       "1  shared_word_lower_threshold_4gram   (6, 47)  0.669782  0.903361  0.769231   \n",
       "\n",
       "  evaluated_on   tp   fp  fn   tn  \n",
       "0      testset  184   69  25  559  \n",
       "1      testset  215  106  23  543  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_threshold_6gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>testset</td>\n",
       "      <td>162</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shared_word_lower_threshold_5gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>testset</td>\n",
       "      <td>184</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shared_word_lower_threshold_4gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>215</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model threshold      prec    recall    fscore  \\\n",
       "0  shared_word_lower_threshold_6gram   (6, 47)  0.801980  0.843750  0.822335   \n",
       "1  shared_word_lower_threshold_5gram   (6, 47)  0.727273  0.880383  0.796537   \n",
       "2  shared_word_lower_threshold_4gram   (6, 47)  0.669782  0.903361  0.769231   \n",
       "\n",
       "  evaluated_on   tp   fp  fn   tn  \n",
       "0      testset  162   40  30  574  \n",
       "1      testset  184   69  25  559  \n",
       "2      testset  215  106  23  543  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 537 ms, sys: 66.9 ms, total: 604 ms\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "threshold_low = 6\n",
    "threshold_high = 47\n",
    "ngram_size = 6\n",
    "\n",
    "for ngram_size in [4, 5, 6]:\n",
    "    query = f\"\"\"\n",
    "    MATCH p1=(i1:Item {{source: 'abt'}})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {{source: 'buy'}})\n",
    "    WHERE n1 <> n2\n",
    "    AND w.name_degree < {threshold_low}\n",
    "    RETURN i1.subject_id, i2.subject_id\n",
    "    UNION ALL\n",
    "    MATCH p1=(i1:Item {{source: 'abt'}})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {{source: 'buy'}})\n",
    "    WHERE n1 <> n2\n",
    "    AND w.name_degree >= {threshold_low}\n",
    "    AND w.name_degree < {threshold_high}\n",
    "    AND (n1)-[:HAS_WORD_LOWER]->(:WordLower)-[:HAS_{ngram_size}GRAM]->(:NoVocab)<-[:HAS_{ngram_size}GRAM]-(:WordLower)<-[:HAS_WORD_LOWER]-(n2)\n",
    "    RETURN i1.subject_id, i2.subject_id\n",
    "    \"\"\"\n",
    "\n",
    "    #print(query)\n",
    "    df_p = pd.DataFrame(graph.query(query))\n",
    "\n",
    "    if len(df_p) > 0:\n",
    "\n",
    "        df_test_p = df_test.merge(df_p, left_on=['source_id', 'target_id'], right_on=['i1.subject_id', 'i2.subject_id'], how='left')\n",
    "        df_test_p['p'] = df_test_p['i1.subject_id'] > 0\n",
    "\n",
    "        prec, recall, fscore, support = precision_recall_fscore_support(df_test_p['matching'], df_test_p['p'], average='binary')\n",
    "\n",
    "        # store errors\n",
    "        cond_p1 = df_test_p['p'] == True\n",
    "        cond_y1 = df_test_p['matching'] == True\n",
    "\n",
    "        df_tp = df_test_p[cond_p1 & cond_y1]\n",
    "        df_fp = df_test_p[cond_p1 & ~cond_y1]\n",
    "        df_tn = df_test_p[~cond_p1 & ~cond_y1]\n",
    "        df_fn = df_test_p[~cond_p1 & cond_y1]\n",
    "\n",
    "        tp = len(df_tp)\n",
    "        fp = len(df_fp)\n",
    "        fn = len(df_fn)\n",
    "        tn = len(df_tn)\n",
    "\n",
    "        results.append({'model': f'shared_word_lower_threshold_{ngram_size}gram', 'threshold': (threshold_low, threshold_high), 'prec': prec, 'recall': recall, 'fscore': fscore, 'evaluated_on': 'testset', 'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn})\n",
    "\n",
    "    df_results = pd.DataFrame(results).sort_values('fscore', ascending=False).reset_index(drop=True)\n",
    "    display(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "285db3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_threshold_6gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>testset</td>\n",
       "      <td>162</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shared_word_lower_threshold_5gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>testset</td>\n",
       "      <td>184</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shared_word_lower_threshold</td>\n",
       "      <td>6</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shared_word_lower_threshold_4gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>215</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shared_word_lower_threshold</td>\n",
       "      <td>10</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>0.763975</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>testset</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model threshold      prec    recall    fscore  \\\n",
       "0  shared_word_lower_threshold_6gram   (6, 47)  0.801980  0.843750  0.822335   \n",
       "1  shared_word_lower_threshold_5gram   (6, 47)  0.727273  0.880383  0.796537   \n",
       "2        shared_word_lower_threshold         6  0.896226  0.673759  0.769231   \n",
       "3  shared_word_lower_threshold_4gram   (6, 47)  0.669782  0.903361  0.769231   \n",
       "4        shared_word_lower_threshold        10  0.754601  0.763975  0.759259   \n",
       "\n",
       "  evaluated_on   tp   fp  fn   tn  \n",
       "0      testset  162   40  30  574  \n",
       "1      testset  184   69  25  559  \n",
       "2      testset    0    0   0    0  \n",
       "3      testset  215  106  23  543  \n",
       "4      testset    0    0   0    0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_all = pd.read_csv(output_path / 'results.csv')\n",
    "df_results_all = pd.concat([df_results, df_results_all]).fillna(0).sort_values('fscore', ascending=False)\n",
    "df_results_all = df_results_all.astype({'tp': 'int', 'fp': 'int', 'fn': 'int', 'tn': 'int'}).reset_index(drop=True)\n",
    "df_results_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b1c75",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "* sharing 6-grams gives best results\n",
    "* precision went down from `0.896226` to `0.801980` (`-9.4%pt`)\n",
    "* recall went up from `0.673759` to `0.843750` (`+17.0%pt`)\n",
    "* overall f-score went up from `0.769231` to `0.822335` (`+5.3%pt`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69076a",
   "metadata": {},
   "source": [
    "### Idea:\n",
    "\n",
    "_crucial differences_\n",
    "* For words that share a large ngram, what makes the diffference, and is it crucial?\n",
    "* In the case `pslx350h` vs `ps-lx350h` \n",
    "    * largest non-overlapping ngrams: `ps` (2-gram) and `lx350h` (6-gram) -> specific\n",
    "    * difference: `-` -> common\n",
    "\n",
    "_Manufacturers_\n",
    "* Some of the items share words or non-vocabulary ngrams that are manufacturer names.\n",
    "\n",
    "_Model rules as votes_\n",
    "* Rather than creating increasingly complex queries to capture more subtle rules, we might model rules as votes for a match or no-match\n",
    "    * Votes can be positive (ie. sharing rare ngrams) or negative (ie. crucial differences)\n",
    "    * Votes should have some kind of weight (ie. approximate conditional probability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
