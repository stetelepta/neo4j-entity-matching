{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7e7b80-d626-4094-86e9-c62bca2c997c",
   "metadata": {},
   "source": [
    "# Entity Matching using Neo4j - Crucial Differences\n",
    "\n",
    "_Salomon Tetelepta, May 8th 2024_\n",
    "* Last change: May 10th 2024\n",
    "* Explore how to model crucial diffences\n",
    "* Match: What you share is __specific__, what differs is __common__\n",
    "    * _ie. same model identifier, differs by a common separator_\n",
    "* No-Match: What you share is __common__, what differs is __specific__\n",
    "    * _ie. same manufacturer, different model identifier_\n",
    "* No-Match: What you share is __specific__, what differs is a __crucial difference__\n",
    "    * _ie. numerical difference, v12 vs v13_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce18da",
   "metadata": {},
   "source": [
    "<img src=\"../images/8-crucial-differences-principle.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b93c37-f0a9-46c8-82e9-dd7ff1f6f2f0",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722da72e-0aaf-4023-bdc4-22853d1c9cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo4j: 5.17.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j python-dotenv langchain-community --quiet\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -p neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f718c68-90df-407e-87e3-8235c2f06180",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a5300d-35fe-4929-b7a8-ded5d5d64a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from pathlib import Path\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from wordfreq import lossy_tokenize, tokenize, word_frequency\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import neo4j\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836fbd4-fa26-49c7-b758-d01d2fc2e97c",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d7b49c-ce17-42d0-85cc-fe21f86a8318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path settings\n",
    "project_path = Path(os.getcwd()).parent\n",
    "data_path = project_path / \"data\"\n",
    "output_path = project_path / \"output\"\n",
    "\n",
    "database = \"abt-buy\"\n",
    "\n",
    "# load env settings\n",
    "load_dotenv(project_path / \".env\")\n",
    "\n",
    "# reproducability\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351bb5f",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850afb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_substring(str1, str2):\n",
    "    # source gpt 3.5\n",
    "    \n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    \n",
    "    # Create a table to store lengths of longest common suffixes\n",
    "    # of substrings. Initialize the table to zeros.\n",
    "    lcs_table = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Variables to store the length of the longest common substring\n",
    "    # and the ending position of the longest common substring in str1.\n",
    "    longest_length = 0\n",
    "    ending_position = 0\n",
    "    \n",
    "    # Fill the lcs_table in bottom-up manner\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                lcs_table[i][j] = lcs_table[i - 1][j - 1] + 1\n",
    "                if lcs_table[i][j] > longest_length:\n",
    "                    longest_length = lcs_table[i][j]\n",
    "                    ending_position = i\n",
    "            else:\n",
    "                lcs_table[i][j] = 0\n",
    "    \n",
    "    # Extract the longest common substring from str1\n",
    "    longest_substring = str1[ending_position - longest_length:ending_position]\n",
    "    \n",
    "    return longest_substring\n",
    "\n",
    "def get_differences_and_overlap_recursive(str1, str2, sep):\n",
    "    # source: gpt 3.5\n",
    "    \n",
    "    # Find the longest common substring\n",
    "    overlap = longest_common_substring(str1, str2)\n",
    "    \n",
    "    # If there is an overlap, recursively find differences and overlap again\n",
    "    if overlap:\n",
    "        # Find the indices of the overlap in both strings\n",
    "        overlap_index1 = str1.find(overlap)\n",
    "        overlap_index2 = str2.find(overlap)\n",
    "        \n",
    "        # Split the strings at the overlap indices\n",
    "        str1_before_overlap = str1[:overlap_index1]\n",
    "        str1_after_overlap = str1[overlap_index1 + len(overlap):]\n",
    "        \n",
    "        str2_before_overlap = str2[:overlap_index2]\n",
    "        str2_after_overlap = str2[overlap_index2 + len(overlap):]\n",
    "        \n",
    "        # Recursively find differences and overlap for the substrings\n",
    "        differences_before = get_differences_and_overlap_recursive(str1_before_overlap, str2_before_overlap, sep=sep)\n",
    "        differences_after = get_differences_and_overlap_recursive(str1_after_overlap, str2_after_overlap, sep=sep)\n",
    "        \n",
    "        # Merge the differences and overlaps\n",
    "        differences = differences_before[\"differences\"] + differences_after[\"differences\"]\n",
    "        overlap = overlap + \"<SEP!>\" + differences_before[\"overlap_str\"] + differences_after[\"overlap_str\"]\n",
    "    else:\n",
    "        # If there is no overlap, set the differences to the input strings\n",
    "        differences = [str1, str2]\n",
    "    \n",
    "    return {\n",
    "        \"differences\": [d for d in differences if d != \"\"],\n",
    "        \"overlap_str\": overlap,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_differences_and_overlap(str1, str2, sep=\"<SEP!>\"):\n",
    "    # slight adaptation to gpt 3.5 code\n",
    "    \n",
    "    result = get_differences_and_overlap_recursive(str1, str2, sep=sep)\n",
    "    # post-processing to get overlap as list\n",
    "    result['overlap'] = [o for o in result['overlap_str'].split(sep) if o != \"\"]\n",
    "    del result['overlap_str']\n",
    "    return result\n",
    "\n",
    "# # Example usage\n",
    "# str1 = \"ps-lx350h\"\n",
    "# str2 = \"pslx350h\"\n",
    "# result = get_differences_and_overlap(str1, str2)\n",
    "\n",
    "# print(\"Difference:\", result[\"differences\"])\n",
    "# print(\"Overlap:\", result[\"overlap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e720d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers(s):\n",
    "    return bool(re.search(r'\\d', s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbe0a7-229a-47b5-8f9c-88bb567b0889",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d3c50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_buy.csv', '1_abt.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path / 'abt-buy' / 'record_descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4237c131-bcea-41b1-8664-881d6315ebf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>description_x</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price_x</th>\n",
       "      <th>subject_id_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>description_y</th>\n",
       "      <th>price_y</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207390654</td>\n",
       "      <td>Sony Handycam HDR-SR10 High Definition Digital...</td>\n",
       "      <td>16:9 - 2.7' Hybrid LCD</td>\n",
       "      <td>Sony</td>\n",
       "      <td>549.0</td>\n",
       "      <td>33161</td>\n",
       "      <td>Sony High Definition HDV Handycam Camcorder - ...</td>\n",
       "      <td>Sony High Definition HDV Handycam Camcorder - ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33161</td>\n",
       "      <td>207390654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208085180</td>\n",
       "      <td>Pioneer DEH-2000MP Car Audio Player</td>\n",
       "      <td>CD-RW - CD-Text, MP3, WMA, WAV - LCD - 4 - 200...</td>\n",
       "      <td>Pioneer</td>\n",
       "      <td>84.0</td>\n",
       "      <td>36258</td>\n",
       "      <td>D-Link Broadband Cable Modem - DCM202</td>\n",
       "      <td>D-Link Broadband Cable Modem - DCM202/ DOCSIS ...</td>\n",
       "      <td>79.00</td>\n",
       "      <td>36258</td>\n",
       "      <td>208085180</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90125786</td>\n",
       "      <td>Sanus Wall/Ceiling Speaker Mount - WMS3S SILVER</td>\n",
       "      <td>Plastic - 8 lb</td>\n",
       "      <td>Sanus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17417</td>\n",
       "      <td>Sanus 13' - 30' VisionMount Flat Panel TV Silv...</td>\n",
       "      <td>Sanus 13' - 30' VisionMount Flat Panel TV Silv...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>17417</td>\n",
       "      <td>90125786</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id_x                                             name_x  \\\n",
       "0     207390654  Sony Handycam HDR-SR10 High Definition Digital...   \n",
       "1     208085180                Pioneer DEH-2000MP Car Audio Player   \n",
       "2      90125786    Sanus Wall/Ceiling Speaker Mount - WMS3S SILVER   \n",
       "\n",
       "                                       description_x manufacturer  price_x  \\\n",
       "0                             16:9 - 2.7' Hybrid LCD         Sony    549.0   \n",
       "1  CD-RW - CD-Text, MP3, WMA, WAV - LCD - 4 - 200...      Pioneer     84.0   \n",
       "2                                     Plastic - 8 lb        Sanus      NaN   \n",
       "\n",
       "   subject_id_y                                             name_y  \\\n",
       "0         33161  Sony High Definition HDV Handycam Camcorder - ...   \n",
       "1         36258              D-Link Broadband Cable Modem - DCM202   \n",
       "2         17417  Sanus 13' - 30' VisionMount Flat Panel TV Silv...   \n",
       "\n",
       "                                       description_y  price_y  source_id  \\\n",
       "0  Sony High Definition HDV Handycam Camcorder - ...      NaN      33161   \n",
       "1  D-Link Broadband Cable Modem - DCM202/ DOCSIS ...    79.00      36258   \n",
       "2  Sanus 13' - 30' VisionMount Flat Panel TV Silv...    39.99      17417   \n",
       "\n",
       "   target_id  matching  \n",
       "0  207390654     False  \n",
       "1  208085180     False  \n",
       "2   90125786     False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abt and buy records\n",
    "df_abt = pd.read_csv(data_path / 'abt-buy' / 'record_descriptions' / '1_abt.csv', encoding='unicode_escape')\n",
    "df_buy = pd.read_csv(data_path / 'abt-buy' / 'record_descriptions' / '2_buy.csv')\n",
    "\n",
    "# matches - train and validation set\n",
    "df_train = pd.read_csv(data_path / 'abt-buy' / 'gs_train.csv')\n",
    "df_val = pd.read_csv(data_path / 'abt-buy' / 'gs_val.csv')\n",
    "df_test = pd.read_csv(data_path / 'abt-buy' / 'gs_test.csv')\n",
    "\n",
    "# merge records with matches\n",
    "df_abt_merged = df_abt.merge(df_train, left_on='subject_id', right_on='source_id', how='right')\n",
    "df_train_merged = df_buy.merge(df_abt_merged, left_on='subject_id', right_on='target_id', how='right')\n",
    "\n",
    "df_train_merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124aa4ad-667e-4c84-a38c-44c27a3e7fbe",
   "metadata": {},
   "source": [
    "### Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70a5c39-9f21-49b4-905e-1385499f93e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database: abt-buy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'count(n)': 612891}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv('NEO4J_URL'),\n",
    "    username=os.getenv('NEO4J_USER'),\n",
    "    password=os.getenv('NEO4J_PASS')\n",
    ")\n",
    "\n",
    "# create database if does not exist\n",
    "graph._database = \"system\"\n",
    "query = f\"CREATE DATABASE `{database}` IF NOT EXISTS\"\n",
    "graph.query(query)\n",
    "\n",
    "# change to target database\n",
    "graph._database = database\n",
    "print(\"database:\", graph._database)\n",
    "\n",
    "# check nr nodes in the graph\n",
    "graph.query(\"MATCH (n) RETURN count(n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d44fad",
   "metadata": {},
   "source": [
    "### Determine overlap and difference for words sharing rare ngrams\n",
    "\n",
    "Examples:\n",
    "* `kx-tga820b` vs `kxtga820b` -> overlap: [`kx`, `tga820b`], differences: [`-`]\t\n",
    "* `rxv663bl` vs `rxv663bk` -> overlap: [`rxv663b`], differences: [`l`, `k`]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9567d5",
   "metadata": {},
   "source": [
    "#### [TRAIN] Get pairs that share large ngrams - get overlap and differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be79e05c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.3 ms, sys: 1.51 ms, total: 34.8 ms\n",
      "Wall time: 62.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 1.91 s\n",
    "\n",
    "query = \"MATCH p=(i1:Item {source: 'abt'})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_6GRAM]->(:NoVocab)<-[:HAS_6GRAM]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(:Name)<-[:HAS_NAME]-(i2:Item)-[:NO_MATCH]-(i1) RETURN DISTINCT w1.value AS w1, w2.value AS w2, i1\"\n",
    "results = graph.query(query)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_diff_overlap = pd.DataFrame(results).apply(lambda x: pd.Series(get_differences_and_overlap(x[0], x[1])), axis=1)\n",
    "df_results_no_match = pd.concat([df_results, df_diff_overlap], axis=1)\n",
    "df_results_no_match['is_match'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2074a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.4 ms, sys: 1.7 ms, total: 45.1 ms\n",
      "Wall time: 50.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 1.91 s\n",
    "\n",
    "query = \"MATCH p=(i1:Item {source: 'abt'})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_6GRAM]->(:NoVocab)<-[:HAS_6GRAM]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(:Name)<-[:HAS_NAME]-(i2:Item)-[:IS_MATCH]-(i1) RETURN DISTINCT w1.value AS w1, w2.value AS w2, i1\"\n",
    "results = graph.query(query)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_diff_overlap = pd.DataFrame(results).apply(lambda x: pd.Series(get_differences_and_overlap(x[0], x[1])), axis=1)\n",
    "df_results_is_match = pd.concat([df_results, df_diff_overlap], axis=1)\n",
    "df_results_is_match['is_match'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5c73df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>i1</th>\n",
       "      <th>differences</th>\n",
       "      <th>overlap</th>\n",
       "      <th>is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tu1500rd</td>\n",
       "      <td>tu-1500rd</td>\n",
       "      <td>{'subject_id': 6493, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[1500rd, tu]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdrj10</td>\n",
       "      <td>mdrj10/blue</td>\n",
       "      <td>{'subject_id': 7195, 'source': 'abt'}</td>\n",
       "      <td>[/blue]</td>\n",
       "      <td>[mdrj10]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kxts108w</td>\n",
       "      <td>kx-ts108w</td>\n",
       "      <td>{'subject_id': 7936, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[ts108w, kx]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdx565mxrf</td>\n",
       "      <td>cdx-565mxrf</td>\n",
       "      <td>{'subject_id': 11338, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[565mxrf, cdx]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pm1327bk</td>\n",
       "      <td>pm1327</td>\n",
       "      <td>{'subject_id': 13155, 'source': 'abt'}</td>\n",
       "      <td>[bk]</td>\n",
       "      <td>[pm1327]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>earbud</td>\n",
       "      <td>earbuds</td>\n",
       "      <td>{'subject_id': 34548, 'source': 'abt'}</td>\n",
       "      <td>[s]</td>\n",
       "      <td>[earbud]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>earbud</td>\n",
       "      <td>earbuds</td>\n",
       "      <td>{'subject_id': 34559, 'source': 'abt'}</td>\n",
       "      <td>[s]</td>\n",
       "      <td>[earbud]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>icfc1ipmk2blk</td>\n",
       "      <td>icfc1ipmk2whi</td>\n",
       "      <td>{'subject_id': 34637, 'source': 'abt'}</td>\n",
       "      <td>[blk, whi]</td>\n",
       "      <td>[icfc1ipmk2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>icfc1ipmk2wht</td>\n",
       "      <td>icfc1ipmk2blk</td>\n",
       "      <td>{'subject_id': 34638, 'source': 'abt'}</td>\n",
       "      <td>[wht, blk]</td>\n",
       "      <td>[icfc1ipmk2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>bluetooth-enabled</td>\n",
       "      <td>bluetooth</td>\n",
       "      <td>{'subject_id': 35800, 'source': 'abt'}</td>\n",
       "      <td>[-enabled]</td>\n",
       "      <td>[bluetooth]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    w1             w2                                      i1  \\\n",
       "0             tu1500rd      tu-1500rd   {'subject_id': 6493, 'source': 'abt'}   \n",
       "1               mdrj10    mdrj10/blue   {'subject_id': 7195, 'source': 'abt'}   \n",
       "2             kxts108w      kx-ts108w   {'subject_id': 7936, 'source': 'abt'}   \n",
       "3           cdx565mxrf    cdx-565mxrf  {'subject_id': 11338, 'source': 'abt'}   \n",
       "4             pm1327bk         pm1327  {'subject_id': 13155, 'source': 'abt'}   \n",
       "..                 ...            ...                                     ...   \n",
       "163             earbud        earbuds  {'subject_id': 34548, 'source': 'abt'}   \n",
       "164             earbud        earbuds  {'subject_id': 34559, 'source': 'abt'}   \n",
       "165      icfc1ipmk2blk  icfc1ipmk2whi  {'subject_id': 34637, 'source': 'abt'}   \n",
       "166      icfc1ipmk2wht  icfc1ipmk2blk  {'subject_id': 34638, 'source': 'abt'}   \n",
       "167  bluetooth-enabled      bluetooth  {'subject_id': 35800, 'source': 'abt'}   \n",
       "\n",
       "    differences         overlap  is_match  \n",
       "0           [-]    [1500rd, tu]         1  \n",
       "1       [/blue]        [mdrj10]         1  \n",
       "2           [-]    [ts108w, kx]         1  \n",
       "3           [-]  [565mxrf, cdx]         1  \n",
       "4          [bk]        [pm1327]         1  \n",
       "..          ...             ...       ...  \n",
       "163         [s]        [earbud]         0  \n",
       "164         [s]        [earbud]         0  \n",
       "165  [blk, whi]    [icfc1ipmk2]         0  \n",
       "166  [wht, blk]    [icfc1ipmk2]         0  \n",
       "167  [-enabled]     [bluetooth]         0  \n",
       "\n",
       "[423 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_train = pd.concat([df_results_is_match, df_results_no_match], axis=0)\n",
    "df_results_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade7bec",
   "metadata": {},
   "source": [
    "#### [TRAIN] Probability of match given a difference string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ea5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train['differences_str'] = df_results_train['differences'].apply(\";\".join)\n",
    "cond_match = df_results_train.is_match == 1\n",
    "df_diff_is_match_vc = df_results_train[cond_match]['differences_str'].value_counts().to_frame()\n",
    "df_diff_no_match_vc = df_results_train[~cond_match]['differences_str'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f37d559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>is_match</th>\n",
       "      <th>no_match</th>\n",
       "      <th>sum</th>\n",
       "      <th>p_is_match</th>\n",
       "      <th>p_no_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3;1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3;2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>3;5;v</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>8;7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     value  is_match  no_match   sum  p_is_match  p_no_match\n",
       "0        -      90.0       1.0  91.0    0.989011    0.010989\n",
       "1        /      33.0       0.0  33.0    1.000000    0.000000\n",
       "2        h      12.0       1.0  13.0    0.923077    0.076923\n",
       "3        s      10.0       6.0  16.0    0.625000    0.375000\n",
       "4       na       5.0       0.0   5.0    1.000000    0.000000\n",
       "..     ...       ...       ...   ...         ...         ...\n",
       "186      3       0.0       1.0   1.0    0.000000    1.000000\n",
       "187    3;1       0.0       1.0   1.0    0.000000    1.000000\n",
       "188    3;2       0.0       1.0   1.0    0.000000    1.000000\n",
       "189  3;5;v       0.0       1.0   1.0    0.000000    1.000000\n",
       "190    8;7       0.0       1.0   1.0    0.000000    1.000000\n",
       "\n",
       "[191 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_differences = df_diff_is_match_vc.merge(df_diff_no_match_vc, left_index=True, right_index=True, how='outer').rename(columns={'differences_str_x': 'is_match', 'differences_str_y': 'no_match'} ).fillna(0)\n",
    "df_differences['sum'] = df_differences.sum(axis=1)\n",
    "df_differences['p_is_match'] = df_differences['is_match'] / df_differences['sum']\n",
    "df_differences['p_no_match'] = df_differences['no_match'] / df_differences['sum']\n",
    "df_differences = df_differences.sort_values('is_match', ascending=False).reset_index(names='value')\n",
    "df_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2f8c1",
   "metadata": {},
   "source": [
    "#### [TRAIN] Mean probability of matches given a numeric value in the differentiating string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95ee5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_is_match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_numbers</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.512606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.162338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             p_is_match\n",
       "has_numbers            \n",
       "False          0.512606\n",
       "True           0.162338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_differences['has_numbers'] = df_differences['value'].apply(has_numbers)\n",
    "df_differences[df_differences['has_numbers'] == True].sort_values('is_match', ascending=False)\n",
    "df_differences.groupby('has_numbers')['p_is_match'].agg('mean').to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a098bf",
   "metadata": {},
   "source": [
    "### Add relationships between WordLower nodes to capture overlap and differences in the graph\n",
    "\n",
    "* Using the training set we determined the probability of a match / no-match for strings that are different (Modelled in the graph as DifferentValues)\n",
    "* To get results on the benchmark, we need to apply this to all the items in the dataset\n",
    "    * Model differences between lowercase words as Nodes: Difference\n",
    "        * `(w1:WordLower)-[:HAS_DIFFERENCE]->(d:Difference)<-[:HAS_DIFFERENCE]-(w2:WordLower)`\n",
    "    * Model the value that makes the difference as DifferentValue, and create a relationship]\n",
    "        * `(d:Difference)-[:HAS_DIFFERENCE_VALUE]-(dv:DifferenceValue)\n",
    "        * Attributes for Difference Values:\n",
    "            * value: concatenated list of values that makes the difference\n",
    "            * degree: number of pair of words that have this value as difference\n",
    "            * p_is_match: that probability that pairs with this difference is a match (training set)\n",
    "            * p_no_match: that probability that pairs with this difference is not a match (training set)\n",
    "            * has_numbers: flag to indicate if the difference contain numbers (indicative for non-matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233977c",
   "metadata": {},
   "source": [
    "#### [TEST] Get pairs that share large ngrams - get overlap and differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a7e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 276 ms, sys: 6.56 ms, total: 283 ms\n",
      "Wall time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 1.91 s\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH p=(i1:Item {source: 'abt'})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_6GRAM]->(:NoVocab)<-[:HAS_6GRAM]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(:Name)<-[:HAS_NAME]-(i2:Item) \n",
    "WHERE NOT (i1)-[:IS_MATCH|NO_MATCH]->(i2)\n",
    "RETURN DISTINCT w1.value AS w1, w2.value AS w2, i1\"\"\"\n",
    "results_test = graph.query(query)\n",
    "\n",
    "df_results_test = pd.DataFrame(results_test)\n",
    "df_diff_overlap_test = pd.DataFrame(results_test).apply(lambda x: pd.Series(get_differences_and_overlap(x[0], x[1])), axis=1)\n",
    "df_results_test = pd.concat([df_results_test, df_diff_overlap_test], axis=1)\n",
    "df_results_test['is_match'] = -1\n",
    "df_results_test['differences_str'] = df_results_test['differences'].apply(\";\".join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53802f",
   "metadata": {},
   "source": [
    "#### Merge differences between WordLower Items with probabilities for the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d01435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train_test = pd.concat([df_results_train, df_results_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b331468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>i1</th>\n",
       "      <th>differences</th>\n",
       "      <th>overlap</th>\n",
       "      <th>is_match</th>\n",
       "      <th>differences_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tu1500rd</td>\n",
       "      <td>tu-1500rd</td>\n",
       "      <td>{'subject_id': 6493, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[1500rd, tu]</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdrj10</td>\n",
       "      <td>mdrj10/blue</td>\n",
       "      <td>{'subject_id': 7195, 'source': 'abt'}</td>\n",
       "      <td>[/blue]</td>\n",
       "      <td>[mdrj10]</td>\n",
       "      <td>1</td>\n",
       "      <td>/blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kxts108w</td>\n",
       "      <td>kx-ts108w</td>\n",
       "      <td>{'subject_id': 7936, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[ts108w, kx]</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdx565mxrf</td>\n",
       "      <td>cdx-565mxrf</td>\n",
       "      <td>{'subject_id': 11338, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[565mxrf, cdx]</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pm1327bk</td>\n",
       "      <td>pm1327</td>\n",
       "      <td>{'subject_id': 13155, 'source': 'abt'}</td>\n",
       "      <td>[bk]</td>\n",
       "      <td>[pm1327]</td>\n",
       "      <td>1</td>\n",
       "      <td>bk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>920000264</td>\n",
       "      <td>920000383</td>\n",
       "      <td>{'subject_id': 39088, 'source': 'abt'}</td>\n",
       "      <td>[264, 383]</td>\n",
       "      <td>[920000]</td>\n",
       "      <td>-1</td>\n",
       "      <td>264;383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>920000264</td>\n",
       "      <td>920000924</td>\n",
       "      <td>{'subject_id': 39088, 'source': 'abt'}</td>\n",
       "      <td>[9, 6]</td>\n",
       "      <td>[920000, 2, 4]</td>\n",
       "      <td>-1</td>\n",
       "      <td>9;6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>981000040</td>\n",
       "      <td>981-000040</td>\n",
       "      <td>{'subject_id': 39175, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[000040, 981]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>wireless-g</td>\n",
       "      <td>wireless-nusb</td>\n",
       "      <td>{'subject_id': 39179, 'source': 'abt'}</td>\n",
       "      <td>[g, nusb]</td>\n",
       "      <td>[wireless-]</td>\n",
       "      <td>-1</td>\n",
       "      <td>g;nusb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>wireless-g</td>\n",
       "      <td>wireless-n</td>\n",
       "      <td>{'subject_id': 39179, 'source': 'abt'}</td>\n",
       "      <td>[g, n]</td>\n",
       "      <td>[wireless-]</td>\n",
       "      <td>-1</td>\n",
       "      <td>g;n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              w1             w2                                      i1  \\\n",
       "0       tu1500rd      tu-1500rd   {'subject_id': 6493, 'source': 'abt'}   \n",
       "1         mdrj10    mdrj10/blue   {'subject_id': 7195, 'source': 'abt'}   \n",
       "2       kxts108w      kx-ts108w   {'subject_id': 7936, 'source': 'abt'}   \n",
       "3     cdx565mxrf    cdx-565mxrf  {'subject_id': 11338, 'source': 'abt'}   \n",
       "4       pm1327bk         pm1327  {'subject_id': 13155, 'source': 'abt'}   \n",
       "...          ...            ...                                     ...   \n",
       "1649   920000264      920000383  {'subject_id': 39088, 'source': 'abt'}   \n",
       "1650   920000264      920000924  {'subject_id': 39088, 'source': 'abt'}   \n",
       "1651   981000040     981-000040  {'subject_id': 39175, 'source': 'abt'}   \n",
       "1652  wireless-g  wireless-nusb  {'subject_id': 39179, 'source': 'abt'}   \n",
       "1653  wireless-g     wireless-n  {'subject_id': 39179, 'source': 'abt'}   \n",
       "\n",
       "     differences         overlap  is_match differences_str  \n",
       "0            [-]    [1500rd, tu]         1               -  \n",
       "1        [/blue]        [mdrj10]         1           /blue  \n",
       "2            [-]    [ts108w, kx]         1               -  \n",
       "3            [-]  [565mxrf, cdx]         1               -  \n",
       "4           [bk]        [pm1327]         1              bk  \n",
       "...          ...             ...       ...             ...  \n",
       "1649  [264, 383]        [920000]        -1         264;383  \n",
       "1650      [9, 6]  [920000, 2, 4]        -1             9;6  \n",
       "1651         [-]   [000040, 981]        -1               -  \n",
       "1652   [g, nusb]     [wireless-]        -1          g;nusb  \n",
       "1653      [g, n]     [wireless-]        -1             g;n  \n",
       "\n",
       "[2077 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248f25ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>i1</th>\n",
       "      <th>differences</th>\n",
       "      <th>overlap</th>\n",
       "      <th>is_match</th>\n",
       "      <th>differences_str</th>\n",
       "      <th>value</th>\n",
       "      <th>no_match</th>\n",
       "      <th>sum</th>\n",
       "      <th>p_is_match</th>\n",
       "      <th>p_no_match</th>\n",
       "      <th>has_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tu1500rd</td>\n",
       "      <td>tu-1500rd</td>\n",
       "      <td>{'subject_id': 6493, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[1500rd, tu]</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdrj10</td>\n",
       "      <td>mdrj10/blue</td>\n",
       "      <td>{'subject_id': 7195, 'source': 'abt'}</td>\n",
       "      <td>[/blue]</td>\n",
       "      <td>[mdrj10]</td>\n",
       "      <td>1</td>\n",
       "      <td>/blue</td>\n",
       "      <td>/blue</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kxts108w</td>\n",
       "      <td>kx-ts108w</td>\n",
       "      <td>{'subject_id': 7936, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[ts108w, kx]</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdx565mxrf</td>\n",
       "      <td>cdx-565mxrf</td>\n",
       "      <td>{'subject_id': 11338, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[565mxrf, cdx]</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pm1327bk</td>\n",
       "      <td>pm1327</td>\n",
       "      <td>{'subject_id': 13155, 'source': 'abt'}</td>\n",
       "      <td>[bk]</td>\n",
       "      <td>[pm1327]</td>\n",
       "      <td>1</td>\n",
       "      <td>bk</td>\n",
       "      <td>bk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>0100057730</td>\n",
       "      <td>0100057600</td>\n",
       "      <td>{'subject_id': 39039, 'source': 'abt'}</td>\n",
       "      <td>[73, 6, 0]</td>\n",
       "      <td>[0100057, 0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>73;6;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>0100057730</td>\n",
       "      <td>0100057610</td>\n",
       "      <td>{'subject_id': 39039, 'source': 'abt'}</td>\n",
       "      <td>[73, 61]</td>\n",
       "      <td>[0100057, 0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>73;61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>920000264</td>\n",
       "      <td>920000383</td>\n",
       "      <td>{'subject_id': 39088, 'source': 'abt'}</td>\n",
       "      <td>[264, 383]</td>\n",
       "      <td>[920000]</td>\n",
       "      <td>-1</td>\n",
       "      <td>264;383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>920000264</td>\n",
       "      <td>920000924</td>\n",
       "      <td>{'subject_id': 39088, 'source': 'abt'}</td>\n",
       "      <td>[9, 6]</td>\n",
       "      <td>[920000, 2, 4]</td>\n",
       "      <td>-1</td>\n",
       "      <td>9;6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>981000040</td>\n",
       "      <td>981-000040</td>\n",
       "      <td>{'subject_id': 39175, 'source': 'abt'}</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[000040, 981]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1597 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              w1           w2                                      i1  \\\n",
       "0       tu1500rd    tu-1500rd   {'subject_id': 6493, 'source': 'abt'}   \n",
       "1         mdrj10  mdrj10/blue   {'subject_id': 7195, 'source': 'abt'}   \n",
       "2       kxts108w    kx-ts108w   {'subject_id': 7936, 'source': 'abt'}   \n",
       "3     cdx565mxrf  cdx-565mxrf  {'subject_id': 11338, 'source': 'abt'}   \n",
       "4       pm1327bk       pm1327  {'subject_id': 13155, 'source': 'abt'}   \n",
       "...          ...          ...                                     ...   \n",
       "1592  0100057730   0100057600  {'subject_id': 39039, 'source': 'abt'}   \n",
       "1593  0100057730   0100057610  {'subject_id': 39039, 'source': 'abt'}   \n",
       "1594   920000264    920000383  {'subject_id': 39088, 'source': 'abt'}   \n",
       "1595   920000264    920000924  {'subject_id': 39088, 'source': 'abt'}   \n",
       "1596   981000040   981-000040  {'subject_id': 39175, 'source': 'abt'}   \n",
       "\n",
       "     differences         overlap  is_match differences_str  value  no_match  \\\n",
       "0            [-]    [1500rd, tu]         1               -      -       1.0   \n",
       "1        [/blue]        [mdrj10]         1           /blue  /blue       0.0   \n",
       "2            [-]    [ts108w, kx]         1               -      -       1.0   \n",
       "3            [-]  [565mxrf, cdx]         1               -      -       1.0   \n",
       "4           [bk]        [pm1327]         1              bk     bk       0.0   \n",
       "...          ...             ...       ...             ...    ...       ...   \n",
       "1592  [73, 6, 0]    [0100057, 0]        -1          73;6;0    NaN       NaN   \n",
       "1593    [73, 61]    [0100057, 0]        -1           73;61    NaN       NaN   \n",
       "1594  [264, 383]        [920000]        -1         264;383    NaN       NaN   \n",
       "1595      [9, 6]  [920000, 2, 4]        -1             9;6    NaN       NaN   \n",
       "1596         [-]   [000040, 981]        -1               -      -       1.0   \n",
       "\n",
       "       sum  p_is_match  p_no_match has_numbers  \n",
       "0     91.0    0.989011    0.010989       False  \n",
       "1      1.0    1.000000    0.000000       False  \n",
       "2     91.0    0.989011    0.010989       False  \n",
       "3     91.0    0.989011    0.010989       False  \n",
       "4      4.0    1.000000    0.000000       False  \n",
       "...    ...         ...         ...         ...  \n",
       "1592   NaN         NaN         NaN         NaN  \n",
       "1593   NaN         NaN         NaN         NaN  \n",
       "1594   NaN         NaN         NaN         NaN  \n",
       "1595   NaN         NaN         NaN         NaN  \n",
       "1596  91.0    0.989011    0.010989       False  \n",
       "\n",
       "[1597 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_merged = df_results_train_test.drop_duplicates(['w1', 'w2']).merge(df_differences.drop('is_match', axis=1), left_on='differences_str', right_on='value', how='left')\n",
    "df_results_merged.drop_duplicates(['w1', 'w2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d138a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/191\n",
      "50/191\n",
      "100/191\n",
      "150/191\n",
      "\n",
      "    MERGE (:DifferenceValue { value: '8;7', degree: 1.0, p_is_match: 0.000, p_no_match: 1.000, has_numbers: 1} )\n",
      "    \n",
      "0/1597\n",
      "100/1597\n",
      "200/1597\n",
      "300/1597\n",
      "400/1597\n",
      "500/1597\n",
      "600/1597\n",
      "700/1597\n",
      "800/1597\n",
      "900/1597\n",
      "1000/1597\n",
      "1100/1597\n",
      "1200/1597\n",
      "1300/1597\n",
      "1400/1597\n",
      "1500/1597\n",
      "\n",
      "    MATCH (dv:DifferenceValue {value: '-'})\n",
      "    MATCH (w1:WordLower {value: '981000040'})\n",
      "    MATCH (w2:WordLower {value: '981-000040'})\n",
      "    MERGE (d:Difference { value: ['-'], sorted_words: ['981-000040', '981000040'] })-[:HAS_DIFFERENCE_VALUE]->(dv)\n",
      "    MERGE (w1)-[:HAS_DIFFERENCE]->(d)<-[:HAS_DIFFERENCE]-(w2)\n",
      "    \n",
      "CPU times: user 2.05 s, sys: 252 ms, total: 2.3 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 15.2s\n",
    "\n",
    "# delete if exists\n",
    "query = \"MATCH ()-[r:HAS_DIFFERENCE_VALUE]-() DELETE r\"\n",
    "graph.query(query)\n",
    "query = \"MATCH ()-[r:HAS_DIFFERENCE]-() DELETE r\"\n",
    "graph.query(query)\n",
    "query = \"MATCH (n:DifferenceValue) DELETE n\"\n",
    "graph.query(query)\n",
    "query = \"MATCH (n:Difference) DELETE n\"\n",
    "graph.query(query)\n",
    "\n",
    "# add difference value nodes\n",
    "for i, (idx, row) in enumerate(df_differences.iterrows()):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{i}/{len(df_differences)}\")\n",
    "            \n",
    "    query = f\"\"\"\n",
    "    MERGE (:DifferenceValue {{ value: '{row['value']}', degree: {row['sum']}, p_is_match: {row['p_is_match']:.3f}, p_no_match: {row['p_no_match']:.3f}, has_numbers: {row['has_numbers']*1}}} )\n",
    "    \"\"\"\n",
    "    graph.query(query)\n",
    "print(query)\n",
    "\n",
    "# add differences as nodes\n",
    "for i, (idx, row) in enumerate(df_results_merged.iterrows()):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i}/{len(df_results_merged)}\")\n",
    "\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    MATCH (dv:DifferenceValue {{value: '{row['differences_str']}'}})\n",
    "    MATCH (w1:WordLower {{value: '{row['w1']}'}})\n",
    "    MATCH (w2:WordLower {{value: '{row['w2']}'}})\n",
    "    MERGE (d:Difference {{ value: {row['differences']}, sorted_words: {sorted([row['w1'], row['w2']])} }})-[:HAS_DIFFERENCE_VALUE]->(dv)\n",
    "    MERGE (w1)-[:HAS_DIFFERENCE]->(d)<-[:HAS_DIFFERENCE]-(w2)\n",
    "    \"\"\"\n",
    "    \n",
    "    graph.query(query)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f5b46",
   "metadata": {},
   "source": [
    "#### Set display value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f034a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(dv)': 191}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"MATCH (dv:DifferenceValue) SET dv.display_value = dv.value + \" (\" + dv.p_is_match + \")\" RETURN count(dv)\"\"\"\n",
    "graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19839e1c",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe55fd1",
   "metadata": {},
   "source": [
    "_Example where only differences between WordLower nodes are common separators, all of them are a match_\n",
    "<img src=\"../images/9.1-common-differences.jpg?\" width=\"600\">\n",
    "\n",
    "_Example where differences contain a numerical value, in this case none of them are a match_\n",
    "<img src=\"../images/9.2-numerical-differences.jpg?\" width=\"600\">\n",
    "\n",
    "_For some reason if `bk` is the only difference these products are often a match_\n",
    "<img src=\"../images/9.3-unexpected-match.jpg?\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec7677",
   "metadata": {},
   "source": [
    "#### Include differences in model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db16ea3",
   "metadata": {},
   "source": [
    "Best model so far:\n",
    "\n",
    "__Match rules:__\n",
    "* 1. Items that share words (_lowercase_) with a name_degree < 6 `-> MATCH`\n",
    "* 2. Items that share words with a name_degree >= 6 and name_degree < 47 \n",
    "    * share an 6gram that is not a vocabulary word `-> MATCH`\n",
    "* f-score so far: `0.822335`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dbaef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_threshold_6gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>testset</td>\n",
       "      <td>162</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shared_word_lower_threshold_5gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>testset</td>\n",
       "      <td>184</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shared_word_lower_threshold</td>\n",
       "      <td>6</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shared_word_lower_threshold_4gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>215</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shared_word_lower_threshold</td>\n",
       "      <td>10</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>0.763975</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>testset</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model threshold      prec    recall    fscore  \\\n",
       "0  shared_word_lower_threshold_6gram   (6, 47)  0.801980  0.843750  0.822335   \n",
       "1  shared_word_lower_threshold_5gram   (6, 47)  0.727273  0.880383  0.796537   \n",
       "2        shared_word_lower_threshold         6  0.896226  0.673759  0.769231   \n",
       "3  shared_word_lower_threshold_4gram   (6, 47)  0.669782  0.903361  0.769231   \n",
       "4        shared_word_lower_threshold        10  0.754601  0.763975  0.759259   \n",
       "\n",
       "  evaluated_on   tp   fp  fn   tn  \n",
       "0      testset  162   40  30  574  \n",
       "1      testset  184   69  25  559  \n",
       "2      testset    0    0   0    0  \n",
       "3      testset  215  106  23  543  \n",
       "4      testset    0    0   0    0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_all = pd.read_csv(output_path / 'results.csv')\n",
    "df_results_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba978a98",
   "metadata": {},
   "source": [
    "#### Model - rule 2: probability for match of difference values > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "939029ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MATCH p1=(i1:Item {source: 'abt'})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {source: 'buy'})\n",
      "WHERE n1 <> n2\n",
      "AND w.name_degree < 6\n",
      "RETURN i1.subject_id, i2.subject_id\n",
      "UNION ALL\n",
      "MATCH p1=(i1:Item {source: 'abt'})-[:HAS_NAME]-(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_DIFFERENCE]->(d:Difference)<-[:HAS_DIFFERENCE]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {source: 'buy'})\n",
      "WITH p1, d, i1, i2\n",
      "MATCH p2=(d)-[:HAS_DIFFERENCE_VALUE]-(dv:DifferenceValue)\n",
      "WHERE dv.p_is_match > 0.5\n",
      "RETURN i1.subject_id, i2.subject_id\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_common_difference</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>testset</td>\n",
       "      <td>124</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  threshold      prec    recall  \\\n",
       "0  shared_word_lower_common_difference          6  0.905109  0.810458   \n",
       "\n",
       "     fscore evaluated_on   tp  fp  fn   tn  \n",
       "0  0.855172      testset  124  13  29  588  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.2 ms, sys: 11.3 ms, total: 97.6 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "threshold_low = 6\n",
    "\n",
    "# common difference\n",
    "query = f\"\"\"\n",
    "MATCH p1=(i1:Item {{source: 'abt'}})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {{source: 'buy'}})\n",
    "WHERE n1 <> n2\n",
    "AND w.name_degree < {threshold_low}\n",
    "RETURN i1.subject_id, i2.subject_id\n",
    "UNION ALL\n",
    "MATCH p1=(i1:Item {{source: 'abt'}})-[:HAS_NAME]-(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_DIFFERENCE]->(d:Difference)<-[:HAS_DIFFERENCE]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {{source: 'buy'}})\n",
    "WITH p1, d, i1, i2\n",
    "MATCH p2=(d)-[:HAS_DIFFERENCE_VALUE]-(dv:DifferenceValue)\n",
    "WHERE dv.p_is_match > 0.5\n",
    "RETURN i1.subject_id, i2.subject_id\n",
    "\"\"\"\n",
    "\n",
    "print(query)\n",
    "df_p = pd.DataFrame(graph.query(query))\n",
    "\n",
    "if len(df_p) > 0:\n",
    "\n",
    "    df_test_p = df_test.merge(df_p, left_on=['source_id', 'target_id'], right_on=['i1.subject_id', 'i2.subject_id'], how='left')\n",
    "    df_test_p['p'] = df_test_p['i1.subject_id'] > 0\n",
    "\n",
    "    prec, recall, fscore, support = precision_recall_fscore_support(df_test_p['matching'], df_test_p['p'], average='binary')\n",
    "\n",
    "    # store errors\n",
    "    cond_p1 = df_test_p['p'] == True\n",
    "    cond_y1 = df_test_p['matching'] == True\n",
    "\n",
    "    df_tp = df_test_p[cond_p1 & cond_y1]\n",
    "    df_fp = df_test_p[cond_p1 & ~cond_y1]\n",
    "    df_tn = df_test_p[~cond_p1 & ~cond_y1]\n",
    "    df_fn = df_test_p[~cond_p1 & cond_y1]\n",
    "\n",
    "    tp = len(df_tp)\n",
    "    fp = len(df_fp)\n",
    "    fn = len(df_fn)\n",
    "    tn = len(df_tn)\n",
    "\n",
    "    results.append({'model': f'shared_word_lower_common_difference', 'threshold': threshold_low, 'prec': prec, 'recall': recall, 'fscore': fscore, 'evaluated_on': 'testset', 'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn})\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values('fscore', ascending=False).reset_index(drop=True)\n",
    "display(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2db12f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_all = pd.concat([df_results, df_results_all]).sort_values('fscore', ascending=False).reset_index(drop=True).drop_duplicates()\n",
    "df_results_all.to_csv(output_path / \"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de10f1",
   "metadata": {},
   "source": [
    "#### Model - rule 2: probability for match of difference values > 0.5 + No numerical difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c71b7418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MATCH p1=(i1:Item {source: 'abt'})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {source: 'buy'})\n",
      "WHERE n1 <> n2\n",
      "AND w.name_degree < 6\n",
      "RETURN i1.subject_id, i2.subject_id\n",
      "UNION ALL\n",
      "MATCH p1=(i1:Item {source: 'abt'})-[:HAS_NAME]-(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_DIFFERENCE]->(d:Difference)<-[:HAS_DIFFERENCE]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {source: 'buy'})\n",
      "WITH p1, d, i1, i2\n",
      "MATCH p2=(d)-[:HAS_DIFFERENCE_VALUE]-(dv:DifferenceValue)\n",
      "WHERE dv.p_is_match > 0.5\n",
      "AND NOT dv.has_numbers = 1\n",
      "RETURN i1.subject_id, i2.subject_id\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_common_no_numerical_difference</td>\n",
       "      <td>6</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.809211</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>testset</td>\n",
       "      <td>123</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model  threshold      prec  \\\n",
       "0  shared_word_lower_common_no_numerical_difference          6  0.911111   \n",
       "\n",
       "     recall    fscore evaluated_on   tp  fp  fn   tn  \n",
       "0  0.809211  0.857143      testset  123  12  29  589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88.2 ms, sys: 11.9 ms, total: 100 ms\n",
      "Wall time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "threshold_low = 6\n",
    "\n",
    "# common difference\n",
    "query = f\"\"\"\n",
    "MATCH p1=(i1:Item {{source: 'abt'}})-[:HAS_NAME]->(n1:Name)-[:HAS_WORD_LOWER]->(w:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {{source: 'buy'}})\n",
    "WHERE n1 <> n2\n",
    "AND w.name_degree < {threshold_low}\n",
    "RETURN i1.subject_id, i2.subject_id\n",
    "UNION ALL\n",
    "MATCH p1=(i1:Item {{source: 'abt'}})-[:HAS_NAME]-(n1:Name)-[:HAS_WORD_LOWER]->(w1:WordLower)-[:HAS_DIFFERENCE]->(d:Difference)<-[:HAS_DIFFERENCE]-(w2:WordLower)<-[:HAS_WORD_LOWER]-(n2:Name)<-[:HAS_NAME]-(i2:Item {{source: 'buy'}})\n",
    "WITH p1, d, i1, i2\n",
    "MATCH p2=(d)-[:HAS_DIFFERENCE_VALUE]-(dv:DifferenceValue)\n",
    "WHERE dv.p_is_match > 0.5\n",
    "AND NOT dv.has_numbers = 1\n",
    "RETURN i1.subject_id, i2.subject_id\n",
    "\"\"\"\n",
    "\n",
    "print(query)\n",
    "df_p = pd.DataFrame(graph.query(query))\n",
    "\n",
    "if len(df_p) > 0:\n",
    "\n",
    "    df_test_p = df_test.merge(df_p, left_on=['source_id', 'target_id'], right_on=['i1.subject_id', 'i2.subject_id'], how='left')\n",
    "    df_test_p['p'] = df_test_p['i1.subject_id'] > 0\n",
    "\n",
    "    prec, recall, fscore, support = precision_recall_fscore_support(df_test_p['matching'], df_test_p['p'], average='binary')\n",
    "\n",
    "    # store errors\n",
    "    cond_p1 = df_test_p['p'] == True\n",
    "    cond_y1 = df_test_p['matching'] == True\n",
    "\n",
    "    df_tp = df_test_p[cond_p1 & cond_y1]\n",
    "    df_fp = df_test_p[cond_p1 & ~cond_y1]\n",
    "    df_tn = df_test_p[~cond_p1 & ~cond_y1]\n",
    "    df_fn = df_test_p[~cond_p1 & cond_y1]\n",
    "\n",
    "    tp = len(df_tp)\n",
    "    fp = len(df_fp)\n",
    "    fn = len(df_fn)\n",
    "    tn = len(df_tn)\n",
    "\n",
    "    results.append({'model': f'shared_word_lower_common_no_numerical_difference', 'threshold': threshold_low, 'prec': prec, 'recall': recall, 'fscore': fscore, 'evaluated_on': 'testset', 'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn})\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values('fscore', ascending=False).reset_index(drop=True)\n",
    "display(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4d97824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>evaluated_on</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared_word_lower_common_no_numerical_difference</td>\n",
       "      <td>6</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.809211</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>testset</td>\n",
       "      <td>123</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shared_word_lower_common_difference</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>testset</td>\n",
       "      <td>124</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shared_word_lower_threshold_6gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>testset</td>\n",
       "      <td>162</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shared_word_lower_threshold_5gram</td>\n",
       "      <td>(6, 47)</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>testset</td>\n",
       "      <td>184</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shared_word_lower_threshold</td>\n",
       "      <td>6</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>testset</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model threshold      prec  \\\n",
       "0  shared_word_lower_common_no_numerical_difference         6  0.911111   \n",
       "2               shared_word_lower_common_difference         6  0.905109   \n",
       "3                 shared_word_lower_threshold_6gram   (6, 47)  0.801980   \n",
       "4                 shared_word_lower_threshold_5gram   (6, 47)  0.727273   \n",
       "5                       shared_word_lower_threshold         6  0.896226   \n",
       "\n",
       "     recall    fscore evaluated_on   tp  fp  fn   tn  \n",
       "0  0.809211  0.857143      testset  123  12  29  589  \n",
       "2  0.810458  0.855172      testset  124  13  29  588  \n",
       "3  0.843750  0.822335      testset  162  40  30  574  \n",
       "4  0.880383  0.796537      testset  184  69  25  559  \n",
       "5  0.673759  0.769231      testset    0   0   0    0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_all = pd.concat([df_results, df_results_all]).sort_values('fscore', ascending=False).reset_index(drop=True).drop_duplicates()\n",
    "df_results_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44e98fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_all.to_csv(output_path / \"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56080ff",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Model that includes matches items that share something specific (6gram) and have a common differences (derived from training set)\n",
    "\n",
    "__Model 1: Common differences__\n",
    "* 1. Items that share words (_lowercase_) with a name_degree < 6 `-> MATCH`\n",
    "* 2. Items that share non-vocabulary 6grams which differ only with a value that is \"common\"\n",
    "    * common: probablity of a match is > 50% for those values on the training set\n",
    "* precision: `0.905 (+10.3%p)`\n",
    "* recall: `0.810 (-3.33%p)`\n",
    "* f-score: `0.855 (+3.28%p)`\n",
    "\n",
    "__Model 2: Common differences + exclude numerical differences:__\n",
    "* 1. Items that share words (_lowercase_) with a name_degree < 6 `-> MATCH`\n",
    "* 2. Items that share non-vocabulary 6grams which differ only with a value that is \"common\"\n",
    "    * common: probablity of a match is > 50% for those values on the training set\n",
    "* precision: `0.911 (+10.9%p)`\n",
    "* recall: `0.809 (-3.45%p)`\n",
    "* f-score: `0.857 (+3.48%p)`\n",
    "\n",
    "_Taking into account the differences is a big win for precision. This model loses a bit of recall, but the increase in precision gives a better fscore_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe93c98",
   "metadata": {},
   "source": [
    "### Examples of False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b90c4",
   "metadata": {},
   "source": [
    "_1. Items mention the same product, but one of them is an add-on for that product_\n",
    "\n",
    "* ABT: Panasonic 5.8GHz Add-On <b>Handset For</b> The KXTG6700B Phone System - Black Finish - KXTGA670B\n",
    "* BUY: Panasonic KX-TG6700B Cordless Telephone\n",
    "<img src=\"../images/10.1-FP-addon-same-product.jpg?\" width=\"600\">\n",
    "<hr>\n",
    "\n",
    "_2. Items share a 6gram, but it is in fact the manufacturer with a slightly different spelling_\n",
    "* ABT: sennheis<b>s</b>er\n",
    "* BUY: sennheiser\n",
    "\n",
    "What is missed by the model is the crucial difference that the version of the model identifier is different\n",
    "* ABT: Sennheisser Hi-Fi Wireless Headphone - <b>RS120</b>\n",
    "* BUY: Sennheiser RS 130 Wireless Headphone - <b>RS130</b>\n",
    "\n",
    "<br>\n",
    "<img src=\"../images/10.2-FP-addon-same-product.jpg?\" width=\"600\">\n",
    "<hr>\n",
    "\n",
    "_3. Model learned that diffentiating value `bl` is common (80% training-set match), but there are exceptions_\n",
    "* ABT: Yamaha <b>NS-AW390BL</b> All-Weather Pair Speaker System - NSAW390BK\n",
    "* BUY: Yamaha Outdoor <b>NS-AW390</b> All-Weather Speaker System - NS-AW390WH\n",
    "\n",
    "<img src=\"../images/10.3-FP-probablity-match.jpg?\" width=\"600\">\n",
    "<img src=\"../images/10.4-FP-probablity-match-exceptions.jpg?\" width=\"800\">\n",
    "<hr>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
